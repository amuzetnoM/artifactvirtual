# Orchestrator core logic
from .tool_registry import ToolRegistry
from .model_loader import ModelLoader
from .command_manual import COMMAND_MANUAL
from .task_queue import Task, TaskQueue
import json
import re
# Llama-3 + DSPy + Persistent Memory Orchestrator
try:
    import dspy
except ImportError:
    dspy = None
try:
    from ollama import Client as OllamaClient
except ImportError:
    OllamaClient = None
try:
    import psycopg2
except ImportError:
    psycopg2 = None
try:
    import pgvector
except ImportError:
    pgvector = None

class CockpitOrchestrator:
    def __init__(self):
        self.tool_registry = ToolRegistry()
        self.model_loader = ModelLoader()
        self.task_queue = TaskQueue()
        self.chat_history = []
        # Placeholder for session/context management
        self.ollama = OllamaClient() if OllamaClient else None
        self.llm = self._load_llama3() if self.ollama else None
        self.dspy = dspy
        self.pg_conn = self._init_pgvector() if psycopg2 and pgvector else None

    def _call_gemma3(self, prompt):
        # Placeholder: Replace with actual Gemma3 inference call
        # Enhanced: parse for file creation and content
        create_match = re.search(r"create ([^\s]+(?:\.\w+)?)(?: in ([^\s]+))?(?: and populate it with (.+))?$", prompt, re.I)
        if create_match:
            filename = create_match.group(1).strip().replace(' ', '_')
            folder = create_match.group(2).strip() if create_match.group(2) else ''
            content = create_match.group(3).strip() if create_match.group(3) else 'Created by Cockpit'
            if folder:
                filepath = f"{folder}\\{filename}" if not filename.startswith(folder) else filename
            else:
                filepath = filename
            # Use echo + Set-Content for best compatibility
            return f'echo {content} | Set-Content {filepath}'
        # Fallback: try to extract file and content from prompt
        fallback_match = re.search(r"create ([^\s]+(?:\.\w+)?).*populate.*with (.+)", prompt, re.I)
        if fallback_match:
            filename = fallback_match.group(1).strip().replace(' ', '_')
            content = fallback_match.group(2).strip()
            return f'echo {content} | Set-Content {filename}'
        # Fallback to previous logic
        if re.search(r"markdown|report|file|create|generate", prompt, re.I):
            return "echo '# Report`nGenerated by Cockpit' | Set-Content report.md"
        return prompt

    def _map_to_cli(self, step):
        # Enhanced mapping: try to convert natural language to CLI if possible
        import re
        # Direct command match
        if step.strip().split()[0] in COMMAND_MANUAL:
            return step
        # Open folder/file logic for Windows
        open_match = re.search(r"open (.+)", step, re.I)
        if open_match:
            target = open_match.group(1).strip()
            # Map common folder names to user directories
            folder_map = {
                'documents': 'C:\\Users\\%USERNAME%\\Documents',
                'music': 'C:\\Users\\%USERNAME%\\Music',
                'pictures': 'C:\\Users\\%USERNAME%\\Pictures',
                'downloads': 'C:\\Users\\%USERNAME%\\Downloads',
                'desktop': 'C:\\Users\\%USERNAME%\\Desktop',
            }
            # If it's a mapped folder, use the full path
            target_lower = target.lower()
            if target_lower in folder_map:
                path = folder_map[target_lower]
            elif re.match(r'^[a-zA-Z]:', target):
                path = target  # Absolute path like C:/ or D:/
            else:
                path = target  # Fallback: use as-is
            return f'explorer.exe {path}'
        # Edit file logic
        edit_match = re.search(r"edit (.+)", step, re.I)
        if edit_match:
            target = edit_match.group(1).strip()
            return f'notepad {target}'
        # Create and write to file logic (PowerShell compatible)
        create_match = re.search(r"create ([^ ]+) and populate it with (.+)", step, re.I)
        if create_match:
            filename = create_match.group(1).strip().replace(' ', '_')
            content = create_match.group(2).strip().replace('"', '`"')
            # Use PowerShell for writing to file
            return f'powershell -Command "\"{content}\" | Set-Content -Path \"{filename}\""'
        # Fallback: try to use notepad for 'open' if it's a file
        file_open_match = re.search(r"open (.+\.\w+)", step, re.I)
        if file_open_match:
            target = file_open_match.group(1).strip()
            return f'notepad {target}'
        return None

    def _lookup_command_manual(self, intent):
        """Search the command manual for relevant commands and usage examples."""
        matches = []
        for cmd, meta in COMMAND_MANUAL.items():
            if cmd in intent.lower() or any(word in intent.lower() for word in meta.get('keywords', [])):
                matches.append({"command": cmd, **meta})
        return matches

    def _reason_about_command(self, intent):
        """Let the LLM (or logic) reason about the best command(s) to use for the intent."""
        # For now, use the manual to suggest the best command(s)
        matches = self._lookup_command_manual(intent)
        if matches:
            # Pick the most relevant command (could be improved with LLM ranking)
            return matches[0]['usage']
        return None

    def _generate_script(self, steps):
        """Generate a PowerShell script for multi-step tasks."""
        script_lines = []
        for step in steps:
            cli_command = self._map_to_cli(step)
            if cli_command:
                script_lines.append(cli_command)
        return '\n'.join(script_lines)

    def _load_llama3(self):
        # Ensure llama3 is pulled in Ollama: ollama pull llama3
        if self.ollama:
            return self.ollama.chat.completions.create(model="llama3", messages=[])
        return None

    def _init_pgvector(self):
        # Connect to PostgreSQL with pgvector extension enabled
        try:
            conn = psycopg2.connect(
                dbname="cockpit_memory",
                user="postgres",
                password="yourpassword",
                host="localhost",
                port=5432
            )
            pgvector.register_vector(conn)
            return conn
        except Exception as e:
            print(f"[Persistent Memory] PostgreSQL connection failed: {e}")
            return None

    def chat(self):
        print("[Cockpit Chat] Type 'exit' to quit.")
        while True:
            user_prompt = input("[User] > ")
            if user_prompt.strip().lower() == 'exit':
                print("[Cockpit] Session ended.")
                break
            self.chat_history.append({"role": "user", "content": user_prompt})
            # LLM intent parsing and plan generation (simulate for now)
            intent = self._call_gemma3(user_prompt)
            print(f"[Intent Parser] Parsed intent: {intent}")

            # Advanced: If user asks for a multi-step task, split and script
            if ';' in intent or 'then' in user_prompt:
                steps = [s.strip() for s in re.split(r';|then', user_prompt) if s.strip()]
                script = self._generate_script(steps)
                print(f"[Script Generated]\n{script}")
                # Optionally, save and execute the script
                with open('generated_script.ps1', 'w', encoding='utf-8') as f:
                    f.write(script)
                print("[Script saved as generated_script.ps1]")
                # Optionally, execute the script (uncomment to enable)
                # result = self.tool_registry.get_tool('cli').execute('powershell -ExecutionPolicy Bypass -File generated_script.ps1')
                # print(f"[Script Execution Result] {result}")
                continue

            # Command manual lookup and reasoning
            manual_matches = self._lookup_command_manual(user_prompt)
            if manual_matches:
                print("[Command Manual Suggestions]:")
                for match in manual_matches:
                    print(json.dumps(match, indent=2))
                best_usage = self._reason_about_command(user_prompt)
                print(f"[Best Usage Example]: {best_usage}")

            # If multiple commands, split and queue
            commands = [c.strip() for c in intent.split(';') if c.strip()]
            tasks = [Task(command=cmd) for cmd in commands]
            for task in tasks:
                self.task_queue.add_task(task)
            # Execute ready tasks
            while not self.task_queue.all_completed():
                ready_tasks = self.task_queue.get_ready_tasks()
                for task in ready_tasks:
                    cli_command = self._map_to_cli(task.command)
                    if cli_command:
                        cli_tool = self.tool_registry.get_tool('cli')
                        result = cli_tool.execute(cli_command)
                        print(f"[CLI Result] {result}")
                    elif 'n8n' in task.command.lower():
                        n8n_tool = self.tool_registry.get_tool('n8n')
                        result = n8n_tool.trigger_workflow('workflow_id', data={'step': task.command})
                        print(f"[n8n Result] {result}")
                    else:
                        print(f"[Tool Orchestrator] No tool matched for: {task.command}")
                    self.task_queue.mark_completed(task)
                    self.chat_history.append({"role": "system", "content": str(result)})
            print("[Cockpit] All tasks completed.")

    def run(self):
        self.chat()
